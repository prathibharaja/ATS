{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36d7b1-6d17-4dcc-b517-a083fab5b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.flush_and_unmount()  # This unmounts the drive cleanly\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f511479-3da0-4704-aad7-557a087ad254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f89e0f-1b4c-4290-a490-f21c891d14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4a27e-0559-4330-a2ad-4dba1ba6d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from google.colab import drive\n",
    "\n",
    "# Define a custom stopword list\n",
    "def custom_stopwords():\n",
    "    return set([\n",
    "        \"the\", \"and\", \"a\", \"an\", \"to\", \"of\", \"in\", \"is\", \"it\", \"for\", \"on\",\n",
    "        \"this\", \"by\", \"at\", \"from\", \"or\", \"that\", \"with\", \"as\", \"was\",\n",
    "        \"be\", \"not\", \"are\", \"his\", \"they\", \"he\", \"she\", \"their\", \"you\",\n",
    "        \"we\", \"has\", \"have\", \"had\"\n",
    "    ])\n",
    "\n",
    "# Initialize stopword list and stemmer\n",
    "stop_words = custom_stopwords()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Tokenization, stopword removal, and stemming\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Load documents from Google Drive folder.\n",
    "def load_documents(directory):\n",
    "    documents = {}\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'rb') as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                text = ''\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text() or ''\n",
    "                documents[filename] = preprocess_text(text)\n",
    "    return documents\n",
    "\n",
    "# Set the path to your folder inside Google Drive\n",
    "directory = '/content/drive/My Drive/Candidate_list'\n",
    "documents = load_documents(directory)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "vectorized_docs = vectorizer.fit_transform(documents.values())\n",
    "doc_names = list(documents.keys())\n",
    "\n",
    "# Queries to compare\n",
    "queries = {\n",
    "    \"Query A - Data Management Skills\": \"Understanding of Data Management Principles: Basic knowledge of data governance, data quality, and data lifecycle management Excel & Google Sheets: Proficient in data manipulation, analysis, and visualization.SQL/Python: (Ideally) experience in querying databases and performing data analysis tasks\",\n",
    "    \"Query B - Personal Attributes\": \"Strong focus on data accuracy and precision.Communication Skills: Ability to convey complex information clearly and effectively.Organizational Skills: Capable of managing multiple tasks and priorities efficiently.Logistics & Sup ply Chain: A keen interest in the logistics and supply chain sectors.Business Analytics: Passion for analyzing data to drive business decisions.\",\n",
    "}\n",
    "\n",
    "# Score queries against documents\n",
    "results = {}\n",
    "for query_name, query in queries.items():\n",
    "    query = preprocess_text(query)\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    scores = vectorized_docs.dot(query_vector.T).toarray().flatten()\n",
    "    ranked_indices = np.argsort(scores)[::-1]\n",
    "    ranked_docs = [(doc_names[i], scores[i]) for i in ranked_indices[:8]]\n",
    "    results[query_name] = ranked_docs\n",
    "\n",
    "# Display results\n",
    "for query_name, ranked_docs in results.items():\n",
    "    print(f\"Results for {query_name}:\")\n",
    "    for doc, score in ranked_docs:\n",
    "        print(f\"  Document: {doc}, Score: {score:.4f}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
